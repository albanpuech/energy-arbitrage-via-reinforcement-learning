{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataset import get_dataset, add_derivatives\n",
    "from env_continuous import Battery\n",
    "from qlearning import QLearning\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plot import display_profit, display_schedule\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN, PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataset(year=2020)\n",
    "# df_Austria = get_dataset(year=2020, country='Austria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.timestamp.dt.year==2021].reset_index(drop=True)\n",
    "df_eval = df[df.timestamp.dt.year==2020].reset_index(drop=True)\n",
    "df_test = df[df.timestamp.dt.year==2022].reset_index(drop=True)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# df_train[\"scaled_price\"] = scaler.fit_transform(df_train.price.to_numpy().reshape(-1, 1))\n",
    "# df_test[\"scaled_price\"]  = scaler.transform(df_test.price.to_numpy().reshape(-1, 1))\n",
    "\n",
    "rolling_mean_price_hours = 24\n",
    "df_train[\"rolling_mean_price\"] = df_train.price.rolling(rolling_mean_price_hours).mean()\n",
    "df_eval[\"rolling_mean_price\"] = df_eval.price.rolling(rolling_mean_price_hours).mean()\n",
    "df_test[\"rolling_mean_price\"] = df_test.price.rolling(rolling_mean_price_hours).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_history_prices(df, n_days=14, k=3):\n",
    "    cols = []\n",
    "    df[\"p_0\"] = df.price #/ df.price.rolling(n_days*24).mean()\n",
    "    cols.append(\"p_0\")\n",
    "\n",
    "    for i in range(1, k):\n",
    "        cols.append(f\"p_{i}\")\n",
    "        df[f\"p_{i}\"] = df[f\"p_{i-1}\"].shift(1)\n",
    "\n",
    "    # def get_price(i):\n",
    "    #     if i - (24*n_days) < 0:\n",
    "    #         return np.nan\n",
    "    #     return df.p_0[i-(24*(n_days)):i:24].mean()\n",
    "    \n",
    "    df[\"h_0\"] = df.p_0.rolling(n_days*24).apply(lambda x: x[::24].mean())\n",
    "    # df[\"h_0\"] = np.array([get_price(i) for i in range(len(df))])\n",
    "    cols.append(\"h_0\")\n",
    "\n",
    "    for h in range(1, 24):\n",
    "        col_name = f\"h_{h}\"\n",
    "        df[col_name] = df[f\"h_{h-1}\"].shift(1)\n",
    "        cols.append(str(col_name))\n",
    "\n",
    "    return df, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 14\n",
    "k = 5\n",
    "df_train, cols = add_rolling_history_prices(df_train, n_days=n_days, k=k)\n",
    "df_eval, cols = add_rolling_history_prices(df_eval, n_days=n_days, k=k)\n",
    "df_test, cols = add_rolling_history_prices(df_test, n_days=n_days, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hour = (n_days * 24 * 2) + max(24, k) - 3\n",
    "\n",
    "def reward(env, action):\n",
    "    if action == 2:\n",
    "        return env.df.rolling_mean_price[env.hour]-env.df.price[env.hour] \n",
    "    \n",
    "    if action == 0:\n",
    "        return env.df.price[env.hour]-env.df.rolling_mean_price[env.hour]\n",
    "    \n",
    "    return 0\n",
    "\n",
    "reward = None\n",
    "\n",
    "train_env = Battery(df_train,cols,start_hour=start_hour, reward_function=reward)\n",
    "train_env_copy = Battery(df_train,cols,start_hour=start_hour, reward_function=reward)\n",
    "test_env = Battery(df_test,cols,start_hour=start_hour, reward_function=reward)\n",
    "eval_env = Battery(df_eval,cols,start_hour=start_hour, reward_function=reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
    "\n",
    "class Cometlogger(BaseCallback):\n",
    "\n",
    "    \"\"\"\n",
    "    Custom callback to plot additional values in comet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experiment, train_env_copy,eval_env,eval_freq=10000):\n",
    "\n",
    "        super(Cometlogger, self).__init__()\n",
    "        self.eval_env = eval_env\n",
    "        self.train_env = train_env_copy\n",
    "        self.eval_freq = eval_freq\n",
    "        self.experiment = experiment\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "\n",
    "            reward_train, df_optim_train = self.train_env.test(self.model)\n",
    "            reward_eval, df_optim_eval = self.eval_env.test(self.model)\n",
    "\n",
    "            profit_train = - (df_optim_train.price * df_optim_train.schedule).sum() / 10**6\n",
    "            profit_eval = - (df_optim_eval.price * df_optim_eval.schedule).sum() / 10**6\n",
    "\n",
    "            self.experiment.log_metric(\"profit_train\",profit_train )\n",
    "            self.experiment.log_metric(\"profit_eval\",profit_eval )\n",
    "\n",
    "            self.experiment.log_metric(\"reward_train\",reward_train )\n",
    "            self.experiment.log_metric(\"reward_eval\",reward_eval)\n",
    "            print(\"---------\")\n",
    "            print(\"profit_train \", profit_train)\n",
    "            print(\"profit_eval \", profit_eval)\n",
    "            print(\"---------\")\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"GYoAMnAcbnbZ9p1PurkZCaSX0\",\n",
    "    project_name=\"battery-rl\",\n",
    "    workspace=\"albanpuech\",\n",
    ")\n",
    "\n",
    "# Report multiple hyperparameters using a dictionary:\n",
    "hyper_params = {\n",
    "    \"k\":k,\n",
    "    \"n_days\":n_days,\n",
    "    \"rolling_mean_price_hours\": rolling_mean_price_hours,\n",
    "    \"reward\": \"difference of valuations with current price\",\n",
    "#\n",
    "}\n",
    "experiment.log_parameters(hyper_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_code(os.path.abspath(\"env_continuous_nb.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env.reset()\n",
    "\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "logger_callback = Cometlogger(experiment, train_env_copy, eval_env,\n",
    "                              eval_freq=10000)\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs2/\",\n",
    "                             log_path=\"./logs2/\", eval_freq=10000,\n",
    "                             deterministic=True, render=False)\n",
    "callback = CallbackList([logger_callback,eval_callback])\n",
    "\n",
    "model.learn(total_timesteps=len(df_train)*500, callback=callback)\n",
    "experiment.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load('logs/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_reward, df_optim = test_env.test(model)\n",
    "\n",
    "df_optim = df_optim[test_env.start_hour:]\n",
    "display_schedule(df_optim)\n",
    "\n",
    "display_profit(df_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bdfae08e3bf9ffe83b7b25a755cae125f279ebcd910909ee363280db2866d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
